---
metadata:
  title: Reference Pointer Protocol
  version: 1.0.0
  created: 2025-12-05
  maintainer: PianoMan
  status: active
  related:
    schema: ../50_schemas/schema_pointer_syntax_latest.yml
    instructions: ../70_instructions/instr_pointer_loading_latest.yml

purpose: |
  Transform Claude's 30 native memory slots (6KB total) from content storage
  into an INDEX system that references unlimited external context.
  
  Instead of: "User is a software developer who likes..."
  Store: "STARTER:ai_memories/60_knowledge/about_user/identity.yml | PRIORITY:1"

problem_solved: |
  Native memory slots are:
  - Limited to 30 slots × 200 chars = 6KB total
  - Flat (no hierarchy)
  - Static (can't reference dynamic state)
  
  Reference Pointers enable:
  - Hierarchical context loading (files can contain pointers to more files)
  - Dynamic queries against long-term memory
  - Lazy loading (load only what's relevant)
  - Unlimited effective memory through external files

core_concepts:
  pointer:
    definition: "A compact string that identifies WHERE to find context"
    format: "<TYPE>:<TARGET> [| <MODIFIER>:<VALUE>]*"
    max_length: 200  # Must fit in native memory slot
    
  destination_file:
    definition: "YAML file containing actual context content"
    location: "ai_memories/ or ai_general/ hierarchy"
    structure: "header (metadata + summary) + content + optional pointers"
    
  lazy_loading:
    definition: "Load context on-demand based on relevance, not upfront"
    triggers:
      - PRIORITY:1 + LOAD:AUTO → Load at conversation start
      - PRIORITY:2 + LOAD:TOPIC → Load when topic area detected
      - PRIORITY:3 + LOAD:DEMAND → Load only when explicitly needed

pointer_types:
  PATH:
    purpose: "Direct file reference"
    format: "TYPE:relative/path/to/file.yml"
    resolution: "Read file via Desktop Commander"
    example: "STARTER:ai_memories/60_knowledge/about_user/identity.yml"
    
  QUERY:
    purpose: "Dynamic search against long-term memory"
    format: "QUERY:<search terms> [| modifiers]"
    resolution: "Search ai_memories/ using memory_search tool"
    example: "QUERY:CLI coordination issues | SINCE:14d | LIMIT:5"
    
  RECENT:
    purpose: "Retrieve N most recent items from a category"
    format: "RECENT:<category> [| modifiers]"
    categories: [session_summaries, task_completions, decisions, errors]
    example: "RECENT:session_summaries | COUNT:3"

load_behaviors:
  AUTO:
    description: "Load without AI decision at conversation start"
    typical_priority: 1
    use_for: "Identity, core preferences, communication style"
    
  TOPIC:
    description: "Load when related topic detected in conversation"
    typical_priority: 2
    use_for: "Project context, domain knowledge, tool patterns"
    
  DEMAND:
    description: "Load only when explicitly needed or referenced"
    typical_priority: 3
    use_for: "Reference material, specs, deep documentation"

workflow:
  conversation_start:
    - Claude receives native memory slots
    - Recognizes pointer format in slots
    - Loads all PRIORITY:1 + LOAD:AUTO pointers silently
    - Has rich context ready before first response
    
  mid_conversation:
    - User mentions topic matching PRIORITY:2 pointer tags
    - Claude loads relevant TOPIC pointers
    - Context expands dynamically as conversation evolves
    
  on_demand:
    - Claude needs specific reference information
    - Explicitly loads PRIORITY:3 pointer
    - May announce: "Let me check the spec for that..."

slot_allocation_guidance:
  total_slots: 30
  recommended:
    identity_prefs: 3-5    # WHO user is, HOW to communicate
    current_project: 3-5   # WHAT user is working on
    tool_configs: 2-3      # HOW tools are configured
    reference_material: 5-10  # WHAT to look up on demand
    reserved: 5-8          # Future expansion, temp context

anti_patterns:
  - storing_content: "Don't put actual facts in slots - put pointers"
  - loading_everything: "Don't load all pointers upfront - lazy load"
  - deep_chains: "Limit pointer chain depth to 3 to prevent runaway loading"
  - circular_refs: "Track loaded paths to prevent infinite loops"

integration_points:
  memory_user_edits_tool:
    purpose: "CRUD for native memory slots"
    pattern: "Use to add/remove/update pointers"
    
  desktop_commander:
    purpose: "Read destination files"
    pattern: "view or read_file for PATH pointers"
    
  memory_search:  # todo_0039
    purpose: "Execute QUERY pointers"
    pattern: "Search ai_memories/ for relevant chunks"

success_metrics:
  - "Conversation starts with rich context without user re-explaining"
  - "Context grows naturally as topics are discussed"
  - "Reference material loads only when needed"
  - "New Claude instances have same contextual awareness"
